{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leileilllll/leileilllll/blob/main/animal_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qldQ4_au5aBy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "091f4432-f879-4a16-d3f7-8256a0737d67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
            "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
            "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)\n",
        "\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from sklearn.metrics import classification_report, f1_score , confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "# Tensorflow Libraries\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Dropout , BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers,models,Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "s-gEO44fZszu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOoV4qA66JPh"
      },
      "source": [
        "Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCL68ci56UGT"
      },
      "outputs": [],
      "source": [
        "path = \"/images/animals-train/\"\n",
        "\n",
        "\n",
        "data = {\"imgpath\": [] , \"labels\": [] }\n",
        "\n",
        "category = os.listdir(path)\n",
        "for folder in category:\n",
        "    folderpath = os.path.join(path , folder)\n",
        "    filelist = os.listdir(folderpath)\n",
        "    for file in filelist:\n",
        "        fpath = os.path.join(folderpath, file)\n",
        "        data[\"imgpath\"].append(fpath)\n",
        "        data[\"labels\"].append(folder)\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "#Convert labels to numbers\n",
        "lb = LabelEncoder()\n",
        "df['encoded_labels'] = lb.fit_transform(df['labels'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "split the dataset into train & test"
      ],
      "metadata": {
        "id": "p87FL0AYD5i4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, Temp_df = train_test_split(df,  train_size= 0.70 , shuffle=True, random_state=124)\n",
        "valid_df , test_df = train_test_split(Temp_df ,  train_size= 0.70 , shuffle=True, random_state=124)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "valid_df = valid_df.reset_index(drop=True)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "\n",
        "print(\"----------Train-------------\")\n",
        "print(train_df[[\"imgpath\", \"labels\"]].head(5))\n",
        "print(train_df.shape)\n",
        "print(\"--------Validation----------\")\n",
        "print(valid_df[[\"imgpath\", \"labels\"]].head(5))\n",
        "print(valid_df.shape)\n",
        "print(\"----------Test--------------\")\n",
        "print(test_df[[\"imgpath\", \"labels\"]].head(5))\n",
        "print(test_df.shape)"
      ],
      "metadata": {
        "id": "mzHHi895D_AM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "show sample from data"
      ],
      "metadata": {
        "id": "bhXe43oaEEGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,12))\n",
        "for i, row in test_df.sample(n=16).reset_index().iterrows():\n",
        "    plt.subplot(4,4,i+1)\n",
        "    image_path = row['imgpath']\n",
        "    image = Image.open(image_path)\n",
        "    plt.imshow(image)\n",
        "    plt.title(row[\"labels\"])\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G_jxILTNEGPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating dataloaders"
      ],
      "metadata": {
        "id": "6g168FK8EXnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "BATCH_SIZE = 15\n",
        "IMAGE_SIZE = (224, 224)\n",
        "\n",
        "\n",
        "generator = ImageDataGenerator(\n",
        "    preprocessing_function = tf.keras.applications.efficientnet.preprocess_input,\n",
        "    # there could be image augmentation here\n",
        ")\n",
        "\n",
        "# Split the data into three categories.\n",
        "train_images = generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='imgpath',\n",
        "    y_col='labels',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "val_images = generator.flow_from_dataframe(\n",
        "    dataframe=valid_df,\n",
        "    x_col='imgpath',\n",
        "    y_col='labels',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_images = generator.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='imgpath',\n",
        "    y_col='labels',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "7wt6-vNlEZnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model structure"
      ],
      "metadata": {
        "id": "SHyNRcbCEg5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pretained model\n",
        "pretrained_model = tf.keras.applications.EfficientNetB3(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False, # we don`t need a pre-trained top layer (output layer)\n",
        "    weights='imagenet',\n",
        "    pooling='max'\n",
        ")\n",
        "\n",
        "# Freezing the layers of a pretrained neural network\n",
        "for i, layer in enumerate(pretrained_model.layers):\n",
        "    pretrained_model.layers[i].trainable = False"
      ],
      "metadata": {
        "id": "TNCNmgKUEivJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(set(train_images.classes))\n",
        "\n",
        "\n",
        "# Data Augmentation Step\n",
        "augment = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "  layers.experimental.preprocessing.RandomRotation(0.15),\n",
        "  layers.experimental.preprocessing.RandomZoom(0.15),\n",
        "  layers.experimental.preprocessing.RandomContrast(0.15),\n",
        "], name='AugmentationLayer')\n",
        "\n",
        "\n",
        "\n",
        "inputs = layers.Input(shape = (224,224,3), name='inputLayer')\n",
        "x = augment(inputs)\n",
        "pretrain_out = pretrained_model(x, training = False)\n",
        "x = layers.Dense(256)(pretrain_out)\n",
        "x = layers.Activation(activation=\"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.Dropout(0.45)(x)\n",
        "x = layers.Dense(num_classes)(x)\n",
        "outputs = layers.Activation(activation=\"softmax\", dtype=tf.float32, name='activationLayer')(x) # mixed_precision need separated Dense and Activation layers\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(0.0005),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "# model.load_weights('./checkpoints/my_checkpoint')\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "J-O0xcscElMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "training: transfer training"
      ],
      "metadata": {
        "id": "u_Ey63ZnEqrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_images,\n",
        "    steps_per_epoch=len(train_images),\n",
        "    validation_data=val_images,\n",
        "    validation_steps=len(val_images),\n",
        "    epochs=10,\n",
        "    callbacks=[\n",
        "        EarlyStopping(monitor = \"val_loss\", # watch the val loss metric\n",
        "                               patience = 3,\n",
        "                               restore_best_weights = True), # if val loss decreases for 10 epochs in a row, stop training,\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, mode='min')\n",
        "    ]\n",
        ")\n",
        "model.save_weights('./checkpoints/my_checkpoint')"
      ],
      "metadata": {
        "id": "eW8tervsEomQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "display model performance"
      ],
      "metadata": {
        "id": "pQVKA9cmE1fP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define needed variables\n",
        "tr_acc = history.history['accuracy']\n",
        "tr_loss = history.history['loss']\n",
        "val_acc = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "index_loss = np.argmin(val_loss)\n",
        "val_lowest = val_loss[index_loss]\n",
        "index_acc = np.argmax(val_acc)\n",
        "acc_highest = val_acc[index_acc]\n",
        "Epochs = [i+1 for i in range(len(tr_acc))]\n",
        "loss_label = f'best epoch= {str(index_loss + 1)}'\n",
        "acc_label = f'best epoch= {str(index_acc + 1)}'\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize= (20, 8))\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
        "plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
        "plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
        "plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
        "plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y-VBBtIJE4Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training : Fine Tuning"
      ],
      "metadata": {
        "id": "HxtpkTLcE9wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model.trainable = True\n",
        "for layer in pretrained_model.layers:\n",
        "    if isinstance(layer, layers.BatchNormalization): # set BatchNorm layers as not trainable\n",
        "        layer.trainable = False\n",
        "\n",
        "# let`s see first 10 layers\n",
        "for l in pretrained_model.layers[:10]:\n",
        "    print(l.name, l.trainable)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(0.00001), # fine tuning requires very little learning rate\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "# model.load_weights('./checkpoints/my_checkpoint')\n",
        "print(model.summary())\n",
        "history = model.fit(\n",
        "    train_images,\n",
        "    steps_per_epoch=len(train_images),\n",
        "    validation_data=val_images,\n",
        "    validation_steps=len(val_images),\n",
        "    epochs=15,\n",
        "    callbacks=[\n",
        "        EarlyStopping(monitor = \"val_loss\", # watch the val loss metric\n",
        "                               patience = 3,\n",
        "                               restore_best_weights = True), # if val loss decreases for 5 epochs in a row, stop training,\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, mode='min')\n",
        "    ]\n",
        ")\n",
        "model.save_weights('./checkpoints/my_checkpoint')"
      ],
      "metadata": {
        "id": "em9absvCE-qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display model performance"
      ],
      "metadata": {
        "id": "2LTAhzI2FDuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define needed variables\n",
        "tr_acc = history.history['accuracy']\n",
        "tr_loss = history.history['loss']\n",
        "val_acc = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "index_loss = np.argmin(val_loss)\n",
        "val_lowest = val_loss[index_loss]\n",
        "index_acc = np.argmax(val_acc)\n",
        "acc_highest = val_acc[index_acc]\n",
        "Epochs = [i+1 for i in range(len(tr_acc))]\n",
        "loss_label = f'best epoch= {str(index_loss + 1)}'\n",
        "acc_label = f'best epoch= {str(index_acc + 1)}'\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize= (20, 8))\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
        "plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
        "plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
        "plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
        "plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y2Bfv9-aFEO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model.evaluate"
      ],
      "metadata": {
        "id": "HwJ0uWYhFIIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_images, verbose=0)\n",
        "\n",
        "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
        "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
      ],
      "metadata": {
        "id": "7WYXtbJSFIyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "F1 Score / Recall / Precision¶"
      ],
      "metadata": {
        "id": "CqkgHsldFM1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = test_images.classes\n",
        "y_pred = np.argmax(model.predict(test_images), axis = 1)\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "print(\"F1 Score:\", f1)\n",
        "print(classification_report(y_true, y_pred, target_names=test_images.class_indices.keys()))"
      ],
      "metadata": {
        "id": "VcksPsQCFOi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get Predictions"
      ],
      "metadata": {
        "id": "yndoMZC1FQrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = dict(zip(test_images.class_indices.values(), test_images.class_indices.keys()))\n",
        "Predictions = pd.DataFrame({\"Image Index\" : list(range(len(test_images.labels))),\n",
        "                            \"Test Labels\" : test_images.labels,\n",
        "                            \"Test Classes\" : [classes[i] for i in test_images.labels],\n",
        "                            \"Prediction Labels\" : y_pred,\n",
        "                            \"Prediction Classes\" : [classes[i] for i in y_pred],\n",
        "                            \"Path\": test_images.filenames,\n",
        "                            \"Prediction Probability\" : [x for x in np.asarray(tf.reduce_max(model.predict(test_images), axis = 1))]\n",
        "                           })\n",
        "Predictions.head(8)"
      ],
      "metadata": {
        "id": "3nO_vg5MFXwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the most confident errors"
      ],
      "metadata": {
        "id": "Gk47AD0xFZuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "for i, row in Predictions[Predictions[\"Test Labels\"] != Predictions[\"Prediction Labels\"]].sort_values(\"Prediction Probability\").tail(20).reset_index().iterrows():\n",
        "    plt.subplot(5,4,i+1)\n",
        "    image_path = row['Path']\n",
        "    image = Image.open(image_path)\n",
        "    plt.imshow(image)\n",
        "    plt.title(f'TRUE: {row[\"Test Classes\"]} | PRED: {row[\"Prediction Classes\"]}', fontsize=8)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zhbGj1CsFgQr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBp4AhQLUzu6LTRJ3wcIpD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}